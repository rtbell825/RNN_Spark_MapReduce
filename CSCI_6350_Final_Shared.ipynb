{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/spark-3.3.2-bin-hadoop2"
      ],
      "metadata": {
        "id": "NN3OVoqeZksy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "aj-3aMkzZlei"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/sp*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6mifm4HZpAZ",
        "outputId": "bb746fb5-bd06-490d-c326-e66d9e6802cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark-3.1.1-bin-hadoop3.2.tgz\n",
            "\n",
            "/content/spark-3.1.1-bin-hadoop3.2:\n",
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "oPZsc6JFZpnJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $SPARK_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYgym-iYZrfp",
        "outputId": "3e8f9e8a-b726-40cc-ad9e-932773516acf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark-3.1.1-bin-hadoop3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYdym8a7Ztbg",
        "outputId": "0c27c7c8-9bb0-42aa-b8f5-2455777cda44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=bb56f8d6c8563cf12815f6610d71142da46181c16c09d667a1f784d9b4ced5a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9HAslFzZvYp",
        "outputId": "f98360aa-9fca-43f3-8b7d-070b7ffe97ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)  # Property used to format output tables better\\"
      ],
      "metadata": {
        "id": "d6LEwZ5aZxtp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yvaHartRZz7h",
        "outputId": "1eb3e378-191b-4266-dd7b-1399b4a7b2c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.1.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiWERSZZ14I",
        "outputId": "d4a59cdb-3191-431d-aa8d-9eeffffeadf8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the comtrans corpus as the machine translation dataset\n",
        "import nltk\n",
        "nltk.download('comtrans')\n",
        "from nltk.corpus import comtrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DHIQQ79Z3w3",
        "outputId": "155de3ba-3545-4525-8610-f5e033c5eb11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package comtrans to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns a list of 33,334 aligned French sentences from the .txt file\n",
        "als = comtrans.aligned_sents(\"alignment-en-fr.txt\")\n",
        "\n",
        "# Defines the maximum number of allowed English or French words in a sentence\n",
        "VECTOR_LEN = 6\n",
        "WORD_COUNT = 5\n",
        "\n",
        "print(len(als))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQu7bRXRZ5yJ",
        "outputId": "4ca91ab0-03e2-47a0-d3e7-e6cac0b27508"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For every sentence in als make an element in the 'dataset' list of the form (int sentence_num, list<str> english_words, list<str> french_words)\n",
        "dataset = []\n",
        "i = 0\n",
        "for entry in als:\n",
        "    dataset.append((i, entry.words, entry.mots))\n",
        "    i = i + 1\n",
        "\n",
        "#Convert dataset from a list to a RDD, then filter out any sentences with English or French words >= VECTOR_LEN.\n",
        "dataset = spark.sparkContext.parallelize(dataset).filter(lambda x: len(x[1]) < VECTOR_LEN).filter(lambda x: len(x[2]) < VECTOR_LEN)\n",
        "dataset.take(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blv7fE0-Z8CB",
        "outputId": "b3a8ece8-f297-447a-b95c-9e1f246186c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  ['Resumption', 'of', 'the', 'session'],\n",
              "  ['Reprise', 'de', 'la', 'session']),\n",
              " (55, ['Agenda'], ['Ordre', 'des', 'travaux']),\n",
              " (82, ['Thank', 'you', 'very', 'much', '.'], ['Merci', '.']),\n",
              " (162,\n",
              "  ['The', 'debate', 'is', 'closed', '.'],\n",
              "  ['Le', 'débat', 'est', 'clos', '.']),\n",
              " (210,\n",
              "  ['The', 'debate', 'is', 'closed', '.'],\n",
              "  ['Le', 'débat', 'est', 'clos', '.']),\n",
              " (387,\n",
              "  ['The', 'debate', 'is', 'closed', '.'],\n",
              "  ['Le', 'débat', 'est', 'clos', '.']),\n",
              " (500,\n",
              "  ['The', 'debate', 'is', 'closed', '.'],\n",
              "  ['Le', 'débat', 'est', 'clos', '.']),\n",
              " (505,\n",
              "  ['Are', 'there', 'any', 'comments', '?'],\n",
              "  ['Y', 'a-t-il', 'des', 'observations', '?']),\n",
              " (529, ['Thank', 'you', 'very', 'much', '.'], ['Merci', 'beaucoup', '.']),\n",
              " (883, ['With', 'what', 'aim', '?'], ['Pour', 'quoi', 'faire', '?']),\n",
              " (991, ['Why', '?'], ['Pourquoi', '?']),\n",
              " (993, ['No', '.'], ['Non', '.']),\n",
              " (1220, ['VOTE'], ['VOTES']),\n",
              " (1241,\n",
              "  ['EXPLANATIONS', 'OF', 'VOTE-', 'Own', 'resources'],\n",
              "  ['Explications', 'de', 'vote-', 'ressources', 'propres']),\n",
              " (1296, ['.'], ['.']),\n",
              " (1410, ['Why', 'not', '?'], ['Pourquoi', '?']),\n",
              " (1491,\n",
              "  ['And', 'now', 'the', 'Erika', '.'],\n",
              "  ['Et', 'maintenant', 'Erika', '.']),\n",
              " (1492, ['Whose', 'turn', 'is', 'next', '?'], ['À', 'qui', 'le', 'tour', '?']),\n",
              " (1673,\n",
              "  ['They', 'want', 'answers', '.'],\n",
              "  ['Elles', 'veulent', 'des', 'réponses', '.']),\n",
              " (1691,\n",
              "  ['That', 'is', 'the', 'reality', '.'],\n",
              "  ['Telle', 'est', 'la', 'réalité', '.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check that all French/English sentences have the correct maximum number of words\n",
        "X_length_max = dataset.map(lambda x: len(x[1])).reduce(lambda x,y: max(x,y))\n",
        "Y_length_max = dataset.map(lambda x: len(x[2])).reduce(lambda x,y: max(x,y))\n",
        "\n",
        "print(X_length_max)\n",
        "print(Y_length_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cqBzKRJZ-q4",
        "outputId": "d6c3a09d-693c-4676-ef51-9f9531a52102"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset from a RDD to a DF\n",
        "df = dataset.toDF([\"index\", \"English\", \"French\"])\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "w0yLsZYfaCLi",
        "outputId": "f923511f-b598-4d67-fdff-e7f4af9e4d4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----+--------------------+--------------------+\n",
              "|index|             English|              French|\n",
              "+-----+--------------------+--------------------+\n",
              "|    0|[Resumption, of, ...|[Reprise, de, la,...|\n",
              "|   55|            [Agenda]|[Ordre, des, trav...|\n",
              "|   82|[Thank, you, very...|          [Merci, .]|\n",
              "|  162|[The, debate, is,...|[Le, débat, est, ...|\n",
              "|  210|[The, debate, is,...|[Le, débat, est, ...|\n",
              "|  387|[The, debate, is,...|[Le, débat, est, ...|\n",
              "|  500|[The, debate, is,...|[Le, débat, est, ...|\n",
              "|  505|[Are, there, any,...|[Y, a-t-il, des, ...|\n",
              "|  529|[Thank, you, very...|[Merci, beaucoup, .]|\n",
              "|  883|[With, what, aim, ?]|[Pour, quoi, fair...|\n",
              "|  991|            [Why, ?]|       [Pourquoi, ?]|\n",
              "|  993|             [No, .]|            [Non, .]|\n",
              "| 1220|              [VOTE]|             [VOTES]|\n",
              "| 1241|[EXPLANATIONS, OF...|[Explications, de...|\n",
              "| 1296|                 [.]|                 [.]|\n",
              "| 1410|       [Why, not, ?]|       [Pourquoi, ?]|\n",
              "| 1491|[And, now, the, E...|[Et, maintenant, ...|\n",
              "| 1492|[Whose, turn, is,...|[À, qui, le, tour...|\n",
              "| 1673|[They, want, answ...|[Elles, veulent, ...|\n",
              "| 1691|[That, is, the, r...|[Telle, est, la, ...|\n",
              "+-----+--------------------+--------------------+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>index</th><th>English</th><th>French</th></tr>\n",
              "<tr><td>0</td><td>[Resumption, of, ...</td><td>[Reprise, de, la,...</td></tr>\n",
              "<tr><td>55</td><td>[Agenda]</td><td>[Ordre, des, trav...</td></tr>\n",
              "<tr><td>82</td><td>[Thank, you, very...</td><td>[Merci, .]</td></tr>\n",
              "<tr><td>162</td><td>[The, debate, is,...</td><td>[Le, débat, est, ...</td></tr>\n",
              "<tr><td>210</td><td>[The, debate, is,...</td><td>[Le, débat, est, ...</td></tr>\n",
              "<tr><td>387</td><td>[The, debate, is,...</td><td>[Le, débat, est, ...</td></tr>\n",
              "<tr><td>500</td><td>[The, debate, is,...</td><td>[Le, débat, est, ...</td></tr>\n",
              "<tr><td>505</td><td>[Are, there, any,...</td><td>[Y, a-t-il, des, ...</td></tr>\n",
              "<tr><td>529</td><td>[Thank, you, very...</td><td>[Merci, beaucoup, .]</td></tr>\n",
              "<tr><td>883</td><td>[With, what, aim, ?]</td><td>[Pour, quoi, fair...</td></tr>\n",
              "<tr><td>991</td><td>[Why, ?]</td><td>[Pourquoi, ?]</td></tr>\n",
              "<tr><td>993</td><td>[No, .]</td><td>[Non, .]</td></tr>\n",
              "<tr><td>1220</td><td>[VOTE]</td><td>[VOTES]</td></tr>\n",
              "<tr><td>1241</td><td>[EXPLANATIONS, OF...</td><td>[Explications, de...</td></tr>\n",
              "<tr><td>1296</td><td>[.]</td><td>[.]</td></tr>\n",
              "<tr><td>1410</td><td>[Why, not, ?]</td><td>[Pourquoi, ?]</td></tr>\n",
              "<tr><td>1491</td><td>[And, now, the, E...</td><td>[Et, maintenant, ...</td></tr>\n",
              "<tr><td>1492</td><td>[Whose, turn, is,...</td><td>[À, qui, le, tour...</td></tr>\n",
              "<tr><td>1673</td><td>[They, want, answ...</td><td>[Elles, veulent, ...</td></tr>\n",
              "<tr><td>1691</td><td>[That, is, the, r...</td><td>[Telle, est, la, ...</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable that controls the number of dimensions of the word vector in Word2Vec\n",
        "FEATURE_COUNT = 528"
      ],
      "metadata": {
        "id": "yBLFTJw5aDzZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, Word2Vec\n",
        "from pyspark.sql.functions import col, lit\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "import numpy\n",
        "\n",
        "# This function takes in a message and breaks it down into individual words\n",
        "def deconstruct(x):\n",
        "    retList = []\n",
        "    for i in range(len(x[1])):\n",
        "        retList.append((x[0], i, x[1][i].lower()))\n",
        "    return retList\n",
        "\n",
        "def removeIndices(x):\n",
        "  retList = []\n",
        "  for pair in x[1]:\n",
        "    retList.append(pair[1])\n",
        "  return (x[0], retList)\n",
        "\n",
        "def fillEmpties(x):\n",
        "  retList = x[1]\n",
        "  if len(x[1]) < VECTOR_LEN - 1:\n",
        "    num_append = VECTOR_LEN - len(x[1]) - 1\n",
        "    for i in range(num_append):\n",
        "      x[1].append(DenseVector(numpy.zeros(FEATURE_COUNT)))\n",
        "  return (x[0], retList)\n",
        "\n",
        "def convertToNumpy(x):\n",
        "  li = []\n",
        "  for vec in x[1]:\n",
        "    temp = numpy.zeros((FEATURE_COUNT, 1))\n",
        "    for i in range(FEATURE_COUNT):\n",
        "      temp[i] = vec[i]\n",
        "    li.append(temp)\n",
        "  return (x[0], numpy.array(li))\n",
        "\n",
        "# Form a df where each row contains a French word. Index is the sentence index within the corpus, wordIndex is word's index within the sentence, and French contains the French word.\n",
        "french_vocabulary = df.select(['index', 'French']).rdd.flatMap(deconstruct).toDF(['index', 'wordIndex', 'French'])\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"French\", outputCol=\"frenchIndexed\")\n",
        "encoder = OneHotEncoder(inputCol=\"frenchIndexed\", outputCol=\"frenchVector\")\n",
        "french_vocabulary = indexer.fit(french_vocabulary).transform(french_vocabulary)\n",
        "french_vocabulary = encoder.fit(french_vocabulary).transform(french_vocabulary)\n",
        "\n",
        "# test with small iterations, different hyperparameters\n",
        "\n",
        "# Convert the df into a rdd  where each element is a French sentence represented a key-value pair of the form (int sentence_index, list word_vectors)\n",
        "french_vectors = french_vocabulary.select(['index', 'wordIndex', 'frenchVector'])\\\n",
        "  .rdd.map(lambda x: (x[0], [(x[1], x[2])]))\\\n",
        "  .reduceByKey(lambda x, y: x + y)\\\n",
        "  .map(lambda x: (x[0], sorted(list(x[1]), key=lambda x: x[0], reverse=False)))\\\n",
        "  .map(lambda x: (x[0], [(i[0], DenseVector(i[1])) for i in x[1]]))\n",
        "\n",
        "print(french_vectors.take(1))\n",
        "\n",
        "french_vectors = french_vectors.map(removeIndices).map(fillEmpties).map(convertToNumpy)\n",
        "\n",
        "french_vocabulary_size = french_vocabulary.select('French').distinct().count()\n",
        "\n",
        "print(french_vocabulary_size)\n",
        "display(french_vocabulary)\n",
        "print(french_vectors.take(1))\n",
        "len(french_vectors.take(1)[0][1])\n",
        "#french_vocabulary.take(1)[0][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r3ybncR7aFzR",
        "outputId": "4b3929b5-bb7a-46ab-bfcc-51e3e161ee94"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, [(0, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])), (1, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])), (2, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])), (3, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))])]\n",
            "529\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----+---------+-------+-------------+-----------------+\n",
              "|index|wordIndex| French|frenchIndexed|     frenchVector|\n",
              "+-----+---------+-------+-------------+-----------------+\n",
              "|    0|        0|reprise|         31.0| (528,[31],[1.0])|\n",
              "|    0|        1|     de|          9.0|  (528,[9],[1.0])|\n",
              "|    0|        2|     la|          8.0|  (528,[8],[1.0])|\n",
              "|    0|        3|session|         17.0| (528,[17],[1.0])|\n",
              "|   55|        0|  ordre|         41.0| (528,[41],[1.0])|\n",
              "|   55|        1|    des|         12.0| (528,[12],[1.0])|\n",
              "|   55|        2|travaux|        103.0|(528,[103],[1.0])|\n",
              "|   82|        0|  merci|         50.0| (528,[50],[1.0])|\n",
              "|   82|        1|      .|          0.0|  (528,[0],[1.0])|\n",
              "|  162|        0|     le|          2.0|  (528,[2],[1.0])|\n",
              "|  162|        1|  débat|          3.0|  (528,[3],[1.0])|\n",
              "|  162|        2|    est|          1.0|  (528,[1],[1.0])|\n",
              "|  162|        3|   clos|          4.0|  (528,[4],[1.0])|\n",
              "|  162|        4|      .|          0.0|  (528,[0],[1.0])|\n",
              "|  210|        0|     le|          2.0|  (528,[2],[1.0])|\n",
              "|  210|        1|  débat|          3.0|  (528,[3],[1.0])|\n",
              "|  210|        2|    est|          1.0|  (528,[1],[1.0])|\n",
              "|  210|        3|   clos|          4.0|  (528,[4],[1.0])|\n",
              "|  210|        4|      .|          0.0|  (528,[0],[1.0])|\n",
              "|  387|        0|     le|          2.0|  (528,[2],[1.0])|\n",
              "+-----+---------+-------+-------------+-----------------+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>index</th><th>wordIndex</th><th>French</th><th>frenchIndexed</th><th>frenchVector</th></tr>\n",
              "<tr><td>0</td><td>0</td><td>reprise</td><td>31.0</td><td>(528,[31],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>1</td><td>de</td><td>9.0</td><td>(528,[9],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>2</td><td>la</td><td>8.0</td><td>(528,[8],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>3</td><td>session</td><td>17.0</td><td>(528,[17],[1.0])</td></tr>\n",
              "<tr><td>55</td><td>0</td><td>ordre</td><td>41.0</td><td>(528,[41],[1.0])</td></tr>\n",
              "<tr><td>55</td><td>1</td><td>des</td><td>12.0</td><td>(528,[12],[1.0])</td></tr>\n",
              "<tr><td>55</td><td>2</td><td>travaux</td><td>103.0</td><td>(528,[103],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>0</td><td>merci</td><td>50.0</td><td>(528,[50],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>1</td><td>.</td><td>0.0</td><td>(528,[0],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>0</td><td>le</td><td>2.0</td><td>(528,[2],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>1</td><td>débat</td><td>3.0</td><td>(528,[3],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>2</td><td>est</td><td>1.0</td><td>(528,[1],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>3</td><td>clos</td><td>4.0</td><td>(528,[4],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>4</td><td>.</td><td>0.0</td><td>(528,[0],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>0</td><td>le</td><td>2.0</td><td>(528,[2],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>1</td><td>débat</td><td>3.0</td><td>(528,[3],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>2</td><td>est</td><td>1.0</td><td>(528,[1],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>3</td><td>clos</td><td>4.0</td><td>(528,[4],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>4</td><td>.</td><td>0.0</td><td>(528,[0],[1.0])</td></tr>\n",
              "<tr><td>387</td><td>0</td><td>le</td><td>2.0</td><td>(528,[2],[1.0])</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, array([[[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]]))]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Goes through the same steps and converts the english sentences into a paired rdd with elements of the form (int sentence_index, list word_vectors)\n",
        "\n",
        "english_vocabulary = df.select(['index', 'English']).rdd.flatMap(deconstruct).toDF(['index', 'wordIndex', 'English'])\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"English\", outputCol=\"englishIndex\")\n",
        "encoder = OneHotEncoder(inputCol=\"englishIndex\", outputCol=\"englishVector\")\n",
        "english_vocabulary = indexer.fit(english_vocabulary).transform(english_vocabulary)\n",
        "english_vocabulary = encoder.fit(english_vocabulary).transform(english_vocabulary)\n",
        "\n",
        "english_vectors = english_vocabulary.select(['index', 'wordIndex', 'englishVector'])\\\n",
        "  .rdd\\\n",
        "  .map(lambda x: (x[0], [(x[1], x[2])]))\\\n",
        "  .reduceByKey(lambda x, y: x + y)\\\n",
        "  .map(lambda x: (x[0], sorted(list(x[1]), key=lambda x: x[0], reverse=False)))\\\n",
        "  .map(lambda x: (x[0], [(i[0], i[1].toArray()) for i in x[1]]))\\\n",
        "  .map(lambda x: (x[0], [(i[0], numpy.pad(i[1], (0, 60), 'constant', constant_values=(0))) for i in x[1]]))\\\n",
        "  .map(lambda x: (x[0], [(i[0], DenseVector(i[1])) for i in x[1]]))\n",
        "\n",
        "english_vectors = english_vectors.map(removeIndices).map(fillEmpties).map(convertToNumpy)\n",
        "\n",
        "english_vocabulary_size = english_vocabulary.select('English').distinct().count()\n",
        "\n",
        "print(english_vocabulary_size)\n",
        "display(english_vocabulary)\n",
        "english_vectors.take(1)"
      ],
      "metadata": {
        "id": "A54LbyCdaJOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e606d6b-b3f2-4e33-af88-4624458cb813"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----+---------+----------+------------+----------------+\n",
              "|index|wordIndex|   English|englishIndex|   englishVector|\n",
              "+-----+---------+----------+------------+----------------+\n",
              "|    0|        0|resumption|        33.0|(468,[33],[1.0])|\n",
              "|    0|        1|        of|        12.0|(468,[12],[1.0])|\n",
              "|    0|        2|       the|         1.0| (468,[1],[1.0])|\n",
              "|    0|        3|   session|        20.0|(468,[20],[1.0])|\n",
              "|   55|        0|    agenda|        38.0|(468,[38],[1.0])|\n",
              "|   82|        0|     thank|        46.0|(468,[46],[1.0])|\n",
              "|   82|        1|       you|        30.0|(468,[30],[1.0])|\n",
              "|   82|        2|      very|        36.0|(468,[36],[1.0])|\n",
              "|   82|        3|      much|        82.0|(468,[82],[1.0])|\n",
              "|   82|        4|         .|         0.0| (468,[0],[1.0])|\n",
              "|  162|        0|       the|         1.0| (468,[1],[1.0])|\n",
              "|  162|        1|    debate|         3.0| (468,[3],[1.0])|\n",
              "|  162|        2|        is|         2.0| (468,[2],[1.0])|\n",
              "|  162|        3|    closed|         4.0| (468,[4],[1.0])|\n",
              "|  162|        4|         .|         0.0| (468,[0],[1.0])|\n",
              "|  210|        0|       the|         1.0| (468,[1],[1.0])|\n",
              "|  210|        1|    debate|         3.0| (468,[3],[1.0])|\n",
              "|  210|        2|        is|         2.0| (468,[2],[1.0])|\n",
              "|  210|        3|    closed|         4.0| (468,[4],[1.0])|\n",
              "|  210|        4|         .|         0.0| (468,[0],[1.0])|\n",
              "+-----+---------+----------+------------+----------------+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>index</th><th>wordIndex</th><th>English</th><th>englishIndex</th><th>englishVector</th></tr>\n",
              "<tr><td>0</td><td>0</td><td>resumption</td><td>33.0</td><td>(468,[33],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>1</td><td>of</td><td>12.0</td><td>(468,[12],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>2</td><td>the</td><td>1.0</td><td>(468,[1],[1.0])</td></tr>\n",
              "<tr><td>0</td><td>3</td><td>session</td><td>20.0</td><td>(468,[20],[1.0])</td></tr>\n",
              "<tr><td>55</td><td>0</td><td>agenda</td><td>38.0</td><td>(468,[38],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>0</td><td>thank</td><td>46.0</td><td>(468,[46],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>1</td><td>you</td><td>30.0</td><td>(468,[30],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>2</td><td>very</td><td>36.0</td><td>(468,[36],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>3</td><td>much</td><td>82.0</td><td>(468,[82],[1.0])</td></tr>\n",
              "<tr><td>82</td><td>4</td><td>.</td><td>0.0</td><td>(468,[0],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>0</td><td>the</td><td>1.0</td><td>(468,[1],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>1</td><td>debate</td><td>3.0</td><td>(468,[3],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>2</td><td>is</td><td>2.0</td><td>(468,[2],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>3</td><td>closed</td><td>4.0</td><td>(468,[4],[1.0])</td></tr>\n",
              "<tr><td>162</td><td>4</td><td>.</td><td>0.0</td><td>(468,[0],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>0</td><td>the</td><td>1.0</td><td>(468,[1],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>1</td><td>debate</td><td>3.0</td><td>(468,[3],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>2</td><td>is</td><td>2.0</td><td>(468,[2],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>3</td><td>closed</td><td>4.0</td><td>(468,[4],[1.0])</td></tr>\n",
              "<tr><td>210</td><td>4</td><td>.</td><td>0.0</td><td>(468,[0],[1.0])</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  array([[[0.],\n",
              "          [0.],\n",
              "          [0.],\n",
              "          ...,\n",
              "          [0.],\n",
              "          [0.],\n",
              "          [0.]],\n",
              "  \n",
              "         [[0.],\n",
              "          [0.],\n",
              "          [0.],\n",
              "          ...,\n",
              "          [0.],\n",
              "          [0.],\n",
              "          [0.]],\n",
              "  \n",
              "         [[0.],\n",
              "          [1.],\n",
              "          [0.],\n",
              "          ...,\n",
              "          [0.],\n",
              "          [0.],\n",
              "          [0.]],\n",
              "  \n",
              "         [[0.],\n",
              "          [0.],\n",
              "          [0.],\n",
              "          ...,\n",
              "          [0.],\n",
              "          [0.],\n",
              "          [0.]],\n",
              "  \n",
              "         [[0.],\n",
              "          [0.],\n",
              "          [0.],\n",
              "          ...,\n",
              "          [0.],\n",
              "          [0.],\n",
              "          [0.]]]))]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_NODES = 100"
      ],
      "metadata": {
        "id": "6rHYn9LjaL4Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = numpy.random.uniform(-numpy.sqrt(1./FEATURE_COUNT), numpy.sqrt(1./FEATURE_COUNT), (HIDDEN_NODES, FEATURE_COUNT))\n",
        "V = numpy.random.uniform(-numpy.sqrt(1./HIDDEN_NODES), numpy.sqrt(1./HIDDEN_NODES), (FEATURE_COUNT, HIDDEN_NODES))\n",
        "W = numpy.random.uniform(-numpy.sqrt(1./HIDDEN_NODES), numpy.sqrt(1./HIDDEN_NODES), (HIDDEN_NODES, HIDDEN_NODES))\n",
        "b = numpy.zeros((HIDDEN_NODES, 1)) # bias for hidden layer\n",
        "c = numpy.zeros((FEATURE_COUNT, 1)) # bias for output"
      ],
      "metadata": {
        "id": "0CTFyNP6aOuw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions in this cell are based on the work of Javaid Nabi found here:\n",
        "# https://github.com/javaidnabi31/RNN-from-scratch/blob/master/RNN_char_text%20generator.ipynb\n",
        "\n",
        "def softmax(x):\n",
        "  e_x = numpy.exp(x - numpy.max(x))\n",
        "  return e_x / numpy.sum(e_x)\n",
        "\n",
        "def forward(x):\n",
        "  #ret_array = []\n",
        "  hs, os, ycap = {}, {}, {}\n",
        "  hs[-1] = numpy.zeros((HIDDEN_NODES,1))\n",
        "  for t in range(WORD_COUNT):\n",
        "    hs[t] = numpy.tanh(numpy.dot(U,x[0][t]) + numpy.dot(W,hs[t-1]) + b) # hidden state\n",
        "    os[t] = numpy.dot(V,hs[t]) + c # unnormalised log probs\n",
        "    ycap[t] = softmax(os[t])\n",
        "  return (x[0], x[1], hs, ycap)\n",
        "\n",
        "def backward(x): # french sentence, english sentence, hs, ycap\n",
        "  # backward pass: compute gradients going backwards\n",
        "  ret_array = []\n",
        "  dU, dW, dV = numpy.zeros_like(U), numpy.zeros_like(W), numpy.zeros_like(V)\n",
        "  db, dc = numpy.zeros_like(b), numpy.zeros_like(c)\n",
        "  dhnext = numpy.zeros_like(x[2][0])\n",
        "  for t in reversed(range(WORD_COUNT)):\n",
        "    dy = numpy.copy(x[3][t])\n",
        "    #through softmax\n",
        "    dy = x[1][t] - dy # backprop into y\n",
        "    ##calculate dV, dc\n",
        "    dV += numpy.dot(dy, x[2][t].T)\n",
        "    dc += dc\n",
        "    #dh includes gradient from two sides, next cell and current output\n",
        "    dh = numpy.dot(V.T, dy) + dhnext # backprop into h\n",
        "    # backprop through tanh non-linearity\n",
        "    dhrec = (1 - x[2][t] * x[2][t]) * dh  #dhrec is the term used in many equations\n",
        "    db += dhrec\n",
        "    #calculate dU and dW\n",
        "    dU += numpy.dot(dhrec, x[0][t].T)\n",
        "    dW += numpy.dot(dhrec, x[2][t-1].T)\n",
        "    #pass the gradient from next cell to the next iteration.\n",
        "    dhnext = numpy.dot(W.T, dhrec)\n",
        "  # clip to mitigate exploding gradients\n",
        "  for dparam in [dU, dW, dV, db, dc]:\n",
        "    numpy.clip(dparam, -5, 5, out=dparam)\n",
        "  return (x[0], x[1], x[2], x[3], dU, dV, dW, db, dc)\n",
        "\n",
        "def loss(x):\n",
        "  \"\"\"loss for a sequence\"\"\"\n",
        "  ret_sum = 0.0\n",
        "  MSE = 0.0\n",
        "  for t in range(WORD_COUNT):\n",
        "    for i in range(FEATURE_COUNT):\n",
        "      MSE += math.pow(x[0][t][i] - x[1][t][i], 2)\n",
        "    ret_sum += (MSE / FEATURE_COUNT)\n",
        "    MSE = 0.0\n",
        "  return ret_sum / WORD_COUNT"
      ],
      "metadata": {
        "id": "2b-UXSMraQrR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(vector1, vector2):\n",
        "  return numpy.dot(vector1, vector2)/ (numpy.linalg.norm(vector1)*numpy.linalg.norm(vector2))\n",
        "\n",
        "def french_sim(word_vector):\n",
        "  index = numpy.argmax(word_vector)\n",
        "  temp = \"frenchIndexed == \" + str(index)\n",
        "  result = french_vocabulary.select(['French']).where(temp).collect()\n",
        "  return result[0]\n",
        "\n",
        "def english_sim(word_vector):\n",
        "  index = numpy.argmax(word_vector)\n",
        "  temp = \"englishIndex == \" + str(index)\n",
        "  result = english_vocabulary.select(['English']).where(temp).collect()\n",
        "  return result[0]"
      ],
      "metadata": {
        "id": "jDVEoFOfaT55"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Function that adds every matrix in two tuples together\n",
        "def add_tuple_gradients(gradient_tuple1, gradient_tuple2) :\n",
        "  return (gradient_tuple1[0] + gradient_tuple2[0], gradient_tuple1[1] + gradient_tuple2[1], gradient_tuple1[2] + gradient_tuple2[2], gradient_tuple1[3] + gradient_tuple2[3], gradient_tuple1[4] + gradient_tuple2[4])\n",
        "\n",
        "def Gradient_Descent_Training(iterations, learning_rate=0.001, batch_size=16):\n",
        "  iteration_losses = []\n",
        "\n",
        "  smooth_loss = -numpy.log(1.0/FEATURE_COUNT)*FEATURE_COUNT\n",
        "\n",
        "  sample_rdd = french_vectors.keys().takeSample(False, 2)\n",
        "  english_sample = english_vectors.filter(lambda x: x[0] in sample_rdd)\n",
        "  french_sample = french_vectors.filter(lambda x: x[0] in sample_rdd)\n",
        "  sample_rdd = french_sample.join(english_sample)\n",
        "\n",
        "  # Run gradient descent for the given number of iterations\n",
        "  for i in range(iterations) :\n",
        "    # Choose a random batch of English/French sentences from the dataset\n",
        "    selected_sentences = french_vectors.keys().takeSample(False, batch_size)\n",
        "    english_batch_rdd = english_vectors.filter(lambda x: x[0] in selected_sentences)\n",
        "    french_batch_rdd = french_vectors.filter(lambda x: x[0] in selected_sentences)\n",
        "\n",
        "    # Join the english and french rdds so they provide training input in the form of (french_sentence, english sentence)\n",
        "    input_rdd = french_batch_rdd.join(english_batch_rdd)\n",
        "\n",
        "    # Run the forward and backward pass of backpropagation using MapReduce to calculate the gradients\n",
        "    french_gradients_rdd = input_rdd.mapValues(forward).mapValues(backward)\n",
        "\n",
        "    #print(french_gradients_rdd.takeSample(False, 1))\n",
        "\n",
        "    # Average loss\n",
        "    loss_val = french_gradients_rdd.map(lambda x: (x[1][1], x[1][3])).map(loss).reduce(lambda x,y: x + y) / batch_size\n",
        "\n",
        "    global U\n",
        "    global V\n",
        "    global W\n",
        "    global b\n",
        "    global c\n",
        "\n",
        "    U += french_gradients_rdd.map(lambda x: x[1][4]*learning_rate).reduce(lambda x,y: x + y)\n",
        "    V += french_gradients_rdd.map(lambda x: x[1][5]*learning_rate).reduce(lambda x,y: x + y)\n",
        "    W += french_gradients_rdd.map(lambda x: x[1][6]*learning_rate).reduce(lambda x,y: x + y)\n",
        "    b += french_gradients_rdd.map(lambda x: x[1][7]*learning_rate).reduce(lambda x,y: x + y)\n",
        "    c += french_gradients_rdd.map(lambda x: x[1][8]*learning_rate).reduce(lambda x,y: x + y)\n",
        "\n",
        "    smooth_loss = smooth_loss*0.999 + loss_val*0.001\n",
        "\n",
        "    print(\"Iteration \" + str(i))\n",
        "    print(\"Average Smooth Loss \" + str(smooth_loss))\n",
        "    iteration_losses.append(smooth_loss)\n",
        "\n",
        "    if not (i)%10:\n",
        "\n",
        "      processed_sample = sample_rdd.mapValues(forward).map(lambda x: (x[1][0], x[1][1], x[1][3])).collect()\n",
        "\n",
        "      #print(processed_sample[0][2])\n",
        "\n",
        "      for sample in processed_sample:\n",
        "        temp = ''\n",
        "        for word in sample[0]:\n",
        "          #print(french_sim(word))\n",
        "          temp = temp + str(french_sim(word)[0]) + \" \"\n",
        "        print(temp)\n",
        "        temp = ''\n",
        "\n",
        "        for word in sample[1]:\n",
        "          temp = temp + english_sim(word)[0] + \" \"\n",
        "        print(temp)\n",
        "        temp = ''\n",
        "\n",
        "        for t in range(WORD_COUNT):\n",
        "          temp = temp + english_sim(sample[2][t])[0] + \" \"\n",
        "        print(temp)\n",
        "        temp = ''\n",
        "\n",
        "      print()\n",
        "\n",
        "iteration_losses = Gradient_Descent_Training(iterations=100, batch_size=math.floor(english_vectors.count() * 0.95))"
      ],
      "metadata": {
        "id": "rcfOG01daWCY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1fdb29b-0dad-4e7e-ed12-0afdfd22d3c7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\n",
            "Average Smooth Loss 3306.772756369247\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            ". . . . . \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            ". . is . . \n",
            "\n",
            "Iteration 1\n",
            "Average Smooth Loss 3303.465985015973\n",
            "Iteration 2\n",
            "Average Smooth Loss 3300.1625204342395\n",
            "Iteration 3\n",
            "Average Smooth Loss 3296.862359288255\n",
            "Iteration 4\n",
            "Average Smooth Loss 3293.565498296989\n",
            "Iteration 5\n",
            "Average Smooth Loss 3290.2719341883007\n",
            "Iteration 6\n",
            "Average Smooth Loss 3286.9816641303414\n",
            "Iteration 7\n",
            "Average Smooth Loss 3283.694684382083\n",
            "Iteration 8\n",
            "Average Smooth Loss 3280.4109912830104\n",
            "Iteration 9\n",
            "Average Smooth Loss 3277.130582405802\n",
            "Iteration 10\n",
            "Average Smooth Loss 3273.853454059301\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "the the is debate is \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the the is debate is \n",
            "\n",
            "Iteration 11\n",
            "Average Smooth Loss 3270.5796029602425\n",
            "Iteration 12\n",
            "Average Smooth Loss 3267.309025776384\n",
            "Iteration 13\n",
            "Average Smooth Loss 3264.0417182394904\n",
            "Iteration 14\n",
            "Average Smooth Loss 3260.7776779050337\n",
            "Iteration 15\n",
            "Average Smooth Loss 3257.516901675794\n",
            "Iteration 16\n",
            "Average Smooth Loss 3254.2593861913406\n",
            "Iteration 17\n",
            "Average Smooth Loss 3251.00512893304\n",
            "Iteration 18\n",
            "Average Smooth Loss 3247.7541252003393\n",
            "Iteration 19\n",
            "Average Smooth Loss 3244.5063723885537\n",
            "Iteration 20\n",
            "Average Smooth Loss 3241.261867764715\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "( debate ! the . \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the concludes . vote the \n",
            "\n",
            "Iteration 21\n",
            "Average Smooth Loss 3238.0206073025897\n",
            "Iteration 22\n",
            "Average Smooth Loss 3234.7825880124137\n",
            "Iteration 23\n",
            "Average Smooth Loss 3231.547807083097\n",
            "Iteration 24\n",
            "Average Smooth Loss 3228.3162607484182\n",
            "Iteration 25\n",
            "Average Smooth Loss 3225.0879459202306\n",
            "Iteration 26\n",
            "Average Smooth Loss 3221.862859292802\n",
            "Iteration 27\n",
            "Average Smooth Loss 3218.6409977985068\n",
            "Iteration 28\n",
            "Average Smooth Loss 3215.422358192084\n",
            "Iteration 29\n",
            "Average Smooth Loss 3212.206937009566\n",
            "Iteration 30\n",
            "Average Smooth Loss 3208.994731248697\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "( of vote ) . \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is concludes . \n",
            "\n",
            "Iteration 31\n",
            "Average Smooth Loss 3205.7857376798383\n",
            "Iteration 32\n",
            "Average Smooth Loss 3202.579953411248\n",
            "Iteration 33\n",
            "Average Smooth Loss 3199.377374652548\n",
            "Iteration 34\n",
            "Average Smooth Loss 3196.1779984966274\n",
            "Iteration 35\n",
            "Average Smooth Loss 3192.9818217460042\n",
            "Iteration 36\n",
            "Average Smooth Loss 3189.788841078781\n",
            "Iteration 37\n",
            "Average Smooth Loss 3186.5990534130374\n",
            "Iteration 38\n",
            "Average Smooth Loss 3183.412455498156\n",
            "Iteration 39\n",
            "Average Smooth Loss 3180.229044185105\n",
            "Iteration 40\n",
            "Average Smooth Loss 3177.0488164921994\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "( is ) ? ? \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is ? . \n",
            "\n",
            "Iteration 41\n",
            "Average Smooth Loss 3173.8717688416486\n",
            "Iteration 42\n",
            "Average Smooth Loss 3170.6978981968177\n",
            "Iteration 43\n",
            "Average Smooth Loss 3167.5272014337247\n",
            "Iteration 44\n",
            "Average Smooth Loss 3164.359675413526\n",
            "Iteration 45\n",
            "Average Smooth Loss 3161.1953170479273\n",
            "Iteration 46\n",
            "Average Smooth Loss 3158.034122868578\n",
            "Iteration 47\n",
            "Average Smooth Loss 3154.876089839871\n",
            "Iteration 48\n",
            "Average Smooth Loss 3151.7212148518083\n",
            "Iteration 49\n",
            "Average Smooth Loss 3148.569494750707\n",
            "Iteration 50\n",
            "Average Smooth Loss 3145.4209265208297\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "( is is ) ? \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is closed . \n",
            "\n",
            "Iteration 51\n",
            "Average Smooth Loss 3142.2755069525406\n",
            "Iteration 52\n",
            "Average Smooth Loss 3139.1332326620404\n",
            "Iteration 53\n",
            "Average Smooth Loss 3135.9941006399094\n",
            "Iteration 54\n",
            "Average Smooth Loss 3132.8581076734945\n",
            "Iteration 55\n",
            "Average Smooth Loss 3129.725250694087\n",
            "Iteration 56\n",
            "Average Smooth Loss 3126.595526572781\n",
            "Iteration 57\n",
            "Average Smooth Loss 3123.468932308794\n",
            "Iteration 58\n",
            "Average Smooth Loss 3120.3454645193815\n",
            "Iteration 59\n",
            "Average Smooth Loss 3117.225120165898\n",
            "Iteration 60\n",
            "Average Smooth Loss 3114.107896137305\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "that applause the ) ! \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is closed . \n",
            "\n",
            "Iteration 61\n",
            "Average Smooth Loss 3110.9937893278025\n",
            "Iteration 62\n",
            "Average Smooth Loss 3107.8827968416144\n",
            "Iteration 63\n",
            "Average Smooth Loss 3104.774915139695\n",
            "Iteration 64\n",
            "Average Smooth Loss 3101.670141399735\n",
            "Iteration 65\n",
            "Average Smooth Loss 3098.568472358111\n",
            "Iteration 66\n",
            "Average Smooth Loss 3095.4699049737824\n",
            "Iteration 67\n",
            "Average Smooth Loss 3092.3744362501743\n",
            "Iteration 68\n",
            "Average Smooth Loss 3089.2820629323046\n",
            "Iteration 69\n",
            "Average Smooth Loss 3086.192781937636\n",
            "Iteration 70\n",
            "Average Smooth Loss 3083.106590270558\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "that of the ? . \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is closed . \n",
            "\n",
            "Iteration 71\n",
            "Average Smooth Loss 3080.023484911452\n",
            "Iteration 72\n",
            "Average Smooth Loss 3076.943462485706\n",
            "Iteration 73\n",
            "Average Smooth Loss 3073.8665201185613\n",
            "Iteration 74\n",
            "Average Smooth Loss 3070.7926546869744\n",
            "Iteration 75\n",
            "Average Smooth Loss 3067.7218632179365\n",
            "Iteration 76\n",
            "Average Smooth Loss 3064.654142418035\n",
            "Iteration 77\n",
            "Average Smooth Loss 3061.5894893328978\n",
            "Iteration 78\n",
            "Average Smooth Loss 3058.527900903114\n",
            "Iteration 79\n",
            "Average Smooth Loss 3055.469374150413\n",
            "Iteration 80\n",
            "Average Smooth Loss 3052.4139058301944\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "that of ) . ? \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is closed . \n",
            "\n",
            "Iteration 81\n",
            "Average Smooth Loss 3049.361492982685\n",
            "Iteration 82\n",
            "Average Smooth Loss 3046.3121325644483\n",
            "Iteration 83\n",
            "Average Smooth Loss 3043.265821651481\n",
            "Iteration 84\n",
            "Average Smooth Loss 3040.2225569520338\n",
            "Iteration 85\n",
            "Average Smooth Loss 3037.1823354445137\n",
            "Iteration 86\n",
            "Average Smooth Loss 3034.1451541675256\n",
            "Iteration 87\n",
            "Average Smooth Loss 3031.1110100616916\n",
            "Iteration 88\n",
            "Average Smooth Loss 3028.079900301768\n",
            "Iteration 89\n",
            "Average Smooth Loss 3025.051821512559\n",
            "Iteration 90\n",
            "Average Smooth Loss 3022.026770802676\n",
            "merci beaucoup pour cela . \n",
            "thank you for that . \n",
            "vote ? ? . ? \n",
            "le débat est clos . \n",
            "the debate is closed . \n",
            "the debate is debate . \n",
            "\n",
            "Iteration 91\n",
            "Average Smooth Loss 3019.0047451374835\n",
            "Iteration 92\n",
            "Average Smooth Loss 3015.9857414630183\n",
            "Iteration 93\n",
            "Average Smooth Loss 3012.969756779989\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-904a770005cb>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0miteration_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradient_Descent_Training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-904a770005cb>\u001b[0m in \u001b[0;36mGradient_Descent_Training\u001b[0;34m(iterations, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mU\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfrench_gradients_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfrench_gradients_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfrench_gradients_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \"\"\"\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xcn35pqcxo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}